import numpy as np
import torch
import torch.nn.functional as F

import os
import h5py
import argparse
import pandas as pd

from clam_funcs.utils.file_utils import save_pkl, load_pkl
from clam_funcs.utils.utils import *
from clam_funcs.dataset_generic import Generic_MIL_Dataset
from model.eval_utils import Accuracy_Logger
from model.model_utils_common import get_classifier



def compute_attention(model, dataset, args):
    acc_logger = Accuracy_Logger(n_classes=args.n_class)
    model.eval()

    slide_ids = dataset.slide_data['slide_id']
    slide_results = {}
    for i in range(len(dataset)):
        slide_id = slide_ids[i]
        print(slide_id)
        features, label, _ = dataset[i]
        
        attn = get_patches_attn(model,features,label,acc_logger)
        patch_coords = get_patches_coords(slide_id,args)
        print(attn.shape)
        print(patch_coords.shape)
        assert(len(attn)==len(patch_coords))
        slide_results.update({slide_id: {'attn': attn, 'coords': patch_coords}})

    #Check that model is performing as expected
    for i in range(args.n_class):
        c_acc, correct, count = acc_logger.get_summary(i)
        print('class {}: acc {}, correct {}/{}'.format(i, c_acc, correct, count))

    out_path = os.path.join(args.checkpoint_dir,'attention')
    os.makedirs(out_path, exist_ok=True) 
    save_pkl(os.path.join(out_path,f'fold{args.fold}.pkl'),slide_results)
    return out_path

def get_patches_coords(slide_id,args):
    h5_file_path = os.path.join(args.patch_data_dir, f"{slide_id}.h5",)
    with h5py.File(h5_file_path,'r') as hdf5_file:
        coords = hdf5_file['coords'][:]
    return coords


def get_patches_attn(model,features,label,acc_logger):
    features = features.to(device)
    with torch.inference_mode():
        logits, info_dict = model(features)
        pred = torch.topk(logits, 1, dim=1)[1].cpu().numpy()
    acc_logger.log(pred,label)

    attn = info_dict['attn'].detach().cpu().numpy().squeeze()
    return attn


parser = argparse.ArgumentParser(description='')
parser.add_argument('--data_root_dir', type=str, default=None, 
                    help='data directory')
parser.add_argument('--patch_data_dir', type=str, default=None, 
                    help='dir with patches so that coords can be found')
parser.add_argument('--eval_data_csv', type=str, default=None, 
                    help='csv of items to be evaluated on')
parser.add_argument('--embed_dim', type=int, default=1024)
parser.add_argument('--checkpoint_dir', default='./results', help='results directory (default: ./results)')
parser.add_argument('--use_h5', action="store_true",default=False)
parser.add_argument('--model_type', type=str,default="TODO")
parser.add_argument('--augments', nargs='+', help='which augmentations to use (for none use og)', required=True)
args = parser.parse_args()
device=torch.device("cuda" if torch.cuda.is_available() else "cpu")



if __name__ == "__main__":
    print(f"Saving Attention Scores generated by Model {args.checkpoint_dir}")
    args.n_class=3
    args.n_block=2
    args.drop_out=0.0
    args.return_attn = True
    args.fold=2
    dataset = Generic_MIL_Dataset(csv_path = args.eval_data_csv,
                            data_dir= args.data_root_dir,
                            shuffle = False, 
                            seed = 7, 
                            print_info = True,
                            label_dict = {'gbm':0, 'astro':1, 'oligo':2},
                            patient_strat=False,
                            patient_voting='max',
                            ignore=[],
                            augments=args.augments,
                            )
    dataset.load_from_h5(args.use_h5)
    model, _ = get_classifier(args)
    model.load_state_dict(torch.load(os.path.join(args.checkpoint_dir,f's_{args.fold}_checkpoint.pt')))
    model.to(device)
    results_dir = compute_attention(model,dataset,args)
    print(f"Saved results to {results_dir}")
    




